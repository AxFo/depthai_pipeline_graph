#!/usr/bin/env python3

def main():
    import subprocess
    from argparse import ArgumentParser
    import os, signal
    import re
    import sys
    from Qt import QtWidgets, QtCore
    from .NodeGraphQt import NodeGraph, BaseNode, PropertiesBinWidget
    from .NodeGraphQt.constants import ViewerEnum
    import json
    import time
    from threading import Thread


    node_color = {
        "ColorCamera": (241,148,138),
        "MonoCamera": (243,243,243),
        "ImageManip": (174,214,241),
        "VideoEncoder": (190,190,190),

        "NeuralNetwork": (171,235,198),
        "DetectionNetwork": (171,235,198),
        "MobileNetDetectionNetwork": (171,235,198),
        "MobileNetSpatialDetectionNetwork": (171,235,198),
        "YoloDetectionNetwork": (171,235,198),
        "YoloSpatialDetectionNetwork": (171,235,198),
        "SpatialDetectionNetwork": (171,235,198),

        "SPIIn": (242,215,213),
        "XLinkIn": (242,215,213),

        "SPIOut": (230,176,170),
        "XLinkOut": (230,176,170),

        "Script": (249,231,159),

        "StereoDepth": (215,189,226),
        "SpatialLocationCalculator": (215,189,226),

        "EdgeDetector": (248,196,113),
        "FeatureTracker": (248,196,113),
        "ObjectTracker": (248,196,113),
        "IMU": (248,196,113)
    }

    default_node_color = (190,190,190) # For node types that does not appear in 'node_color'


    class DepthaiNode(BaseNode):
        # unique node identifier.
        __identifier__ = 'dai'

        # initial default node name.
        NODE_NAME = 'Node'

        def __init__(self):
            super(DepthaiNode, self).__init__()

            # create QLineEdit text input widget.
            # self.add_text_input('my_input', 'Text Input', tab='widgets')

    parser = ArgumentParser()
    subparsers = parser.add_subparsers(help="Action", required=True, dest="action")

    run_parser = subparsers.add_parser("run", help="Run your depthai program to create the corresponding pipeline graph")
    run_parser.add_argument('command', type=str,
                help="The command with its arguments between ' or \" (ex: python script.py -i file)")
    run_parser.add_argument("-dnk", "--do_not_kill", action="store_true",
                help="Don't terminate the command when the schema string has been retrieved")
    run_parser.add_argument("-var", "--use_variable_names", action="store_true",
                help="Use the variable names from the python code to name the graph nodes")
    run_parser.add_argument("-p", "--pipeline_name", type=str, default="pipeline",
                help="Name of the pipeline variable in the python code (default=%(default)s)")
    run_parser.add_argument('-v', '--verbose', action="store_true",
                help="Show on the console the command output")

    from_file_parser = subparsers.add_parser("from_file",
                help="Create the pipeline graph by parsing a file containing the schema (log file generated with DEPTHAI_LEVEL=debug or Json file generated by pipeline.serializeToJSon())")
    from_file_parser.add_argument("schema_file",
                help="Path of the file containing the schema")

    load_parser = subparsers.add_parser("load", help="Load a previously saved pipeline graph")
    load_parser.add_argument("json_file",
                help="Path of the .json file")
    args = parser.parse_args()

    # handle SIGINT to make the app terminate on CTRL+C
    signal.signal(signal.SIGINT, signal.SIG_DFL)

    QtCore.QCoreApplication.setAttribute(QtCore.Qt.AA_EnableHighDpiScaling)

    app = QtWidgets.QApplication(["DepthAI Pipeline Graph"])

    # create node graph controller.
    graph = NodeGraph()
    graph.set_background_color(255,255,255)
    graph.set_grid_mode(ViewerEnum.GRID_DISPLAY_NONE.value)

    graph.register_node(DepthaiNode)


    # create a node properties bin widget.
    properties_bin = PropertiesBinWidget(node_graph=graph)
    properties_bin.setWindowFlags(QtCore.Qt.Tool)

    # show the node properties bin widget when a node is double clicked.
    def display_properties_bin(node):
        if not properties_bin.isVisible():
            properties_bin.show()
    # wire function to "node_double_clicked" signal.
    graph.node_double_clicked.connect(display_properties_bin)

        # show the node graph widget.
    graph_widget = graph.widget
    graph_widget.resize(1100, 800)

    process = None

    if args.action == "load":

        graph_widget.show()
        graph.load_session(args.json_file)
        graph.fit_to_selection()
        graph.set_zoom(-0.9)
        graph.clear_selection()
        graph.clear_undo_stack()

        app.exec_()

    else:
        if args.action == "run":
            os.environ["PYTHONUNBUFFERED"] = "1"
            os.environ["DEPTHAI_LEVEL"] = "trace"

            command = args.command.split()
            if args.use_variable_names:
                # If command starts with "python", we remove it
                if "python" in command[0]:
                    command.pop(0)

                command = "python -m trace -t ".split() + command
                pipeline_create_re = f'.*:\s*(.*)\s*=\s*{args.pipeline_name}\.create.*'
                node_name = []
            process = subprocess.Popen(command, shell=False, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)

            schema_str = None
            record_output = "" # Save the output and print it in case something went wrong
            while True:
                if process.poll() is not None: break
                line = process.stdout.readline()
                record_output += line
                if args.verbose:
                    print(line.rstrip('\n'))
                # we are looking for  a line:  ... [debug] Schema dump: {"connections":[{"node1Id":1...
                match = re.match(r'.* Schema dump: (.*)', line)
                if match:
                    schema_str = match.group(1)
                    print("Pipeline schema retrieved")
                    break
                    # TODO(themarpe) - expose "do kill" now
                    # # print(schema_str)
                    # if not args.do_not_kill:
                    #     print("Terminating program...")
                    #     process.terminate()
                elif args.use_variable_names:
                    match = re.match(pipeline_create_re, line)
                    if match:
                        node_name.append(match.group(1))
            print("Program exited.")
            if schema_str is None:
                if not args.verbose:
                    print(record_output)
                print("\nSomething went wrong, the schema could not be extracted")
                exit(1)
            schema = json.loads(schema_str)
        elif args.action == "from_file":
            with open(args.schema_file, "r") as schema_file:
                # schema_file is either:
                # 1) a Json file generated by a call to pipeline.serializeToJson(),
                # 2) a log file generated by running the user program with DEPTHAI_LEVEL set to debug

                # Are we in case 1) ?
                try:
                    schema = json.load(schema_file)
                    if 'pipeline' not in schema:
                        print(f"Json file '{args.schema_file}' is missing 'pipeline' key")
                        exit(1)
                    schema = schema['pipeline']
                    print("Pipeline schema retrieved")
                except json.decoder.JSONDecodeError:
                    # schema_file is not a Json file, so we are probably in case 2)
                    # we are looking for  a line:  ... [debug] Schema dump: {"connections":[{"node1Id":1...
                    schema_file.seek(0) # Rewind the file
                    while True:
                        line = schema_file.readline()
                        if len(line) == 0:
                            # End of file
                            print("\nSomething went wrong, the schema could not be extracted")
                            exit(1)
                        match = re.match(r'.* Schema dump: (.*)', line)
                        if match:
                            schema_str = match.group(1)
                            print("Pipeline schema retrieved")
                            break
                    schema = json.loads(schema_str)

        if args.verbose:
            print('Schema:', schema)


        # create the nodes.
        qt_nodes = {}
        dai_connections = schema['connections']
        dai_nodes = {} # key = id, value = dict with keys 'type', 'blocking', 'queue_size' and 'name' (if args.use_variable_name)
        # Hold id->port
        input_port_map = dict()
        output_port_map = dict()
        input_name_to_id_map = dict()
        output_name_to_id_map = dict()

        print("\nNodes (id):\n===========")
        for n in schema['nodes']:
            dict_n = n[1]
            node_name = dict_n['name']
            if args.verbose:
                print(f"{node_name}, {dict_n}")
            else:
                print(f"{node_name}")
            id = dict_n['id']
            dai_nodes[dict_n['id']] = {'type': node_name}
            if args.action == "run" and args.use_variable_names:
                dai_nodes[dict_n['id']]['name'] = f"{node_name} - {node_name[dict_n['id']]}"
            else:
                dai_nodes[dict_n['id']]['name'] = f"{node_name} ({dict_n['id']})"

            # Create the node
            qt_nodes[id] = graph.create_node('dai.DepthaiNode', name=node_name, color=node_color.get(node_name, default_node_color), text_color=(0,0,0), push_undo=False)

            for io in dict_n['ioInfo']:
                dict_io = io[1]
                io_id = dict_io['id']
                port_name = dict_io['name']
                port_group = dict_io['group']
                if port_group:
                    port_name = f"{dict_io['group']}[{port_name}]"
                blocking = dict_io['blocking']
                queue_size = dict_io['queueSize']
                port_color = (249,75,0) if blocking else (0,255,0)
                port_label = f"[{queue_size}] {port_name}"

                io_key = tuple([id, dict_io['group'], dict_io['name']])
                if dict_io['type'] == 3: # Input
                    input_port_map[dict_io['id']] = qt_nodes[id].add_input(name=port_label, color=port_color, multi_input=True)
                    input_name_to_id_map[io_key] = io_id
                elif dict_io['type'] == 0: # Output
                    output_port_map[dict_io['id']] = qt_nodes[id].add_output(name=port_name)
                    output_name_to_id_map[io_key] = io_id
                else:
                    print('Unhandled case!')


        print("\nConnections:\n============")
        i=0
        for c in dai_connections:
            src_node_id = c["node1Id"]
            src_name = c["node1Output"]
            src_group = c["node1OutputGroup"]
            dst_node_id = c["node2Id"]
            dst_name = c["node2Input"]
            dst_group = c["node2InputGroup"]

            out_key = tuple([src_node_id, src_group, src_name])
            in_key = tuple([dst_node_id, dst_group, dst_name])
            print(i,f"{out_key} -> {in_key}")

            output_port_map[output_name_to_id_map[out_key]].connect_to(input_port_map[input_name_to_id_map[in_key]], push_undo=False)
            i+=1

        # Lock the ports
        graph.lock_all_ports()

        graph_widget.show()
        graph.auto_layout_nodes()
        graph.fit_to_selection()
        graph.set_zoom(-0.9)
        graph.clear_selection()
        graph.clear_undo_stack()

        def traceEventReader(proc, buffer):
            # local_event_buffer = []
            while proc.poll() is None:
                line = proc.stdout.readline()
                if args.verbose:
                    print(line.rstrip('\n'))
                # we are looking for  a line: EV:  ...
                match = re.search(r'EV:([0-9]+),S:([0-9]+),IDS:([0-9]+),IDD:([0-9]+),TSS:([0-9]+),TSN:([0-9]+)', line.rstrip('\n'))
                if match:
                    trace_event = TraceEvent()

                    trace_event.event = int(match.group(1))
                    trace_event.status = int(match.group(2))
                    trace_event.src_id = int(match.group(3))
                    trace_event.dst_id = int(match.group(4))
                    trace_event.timestamp = int(match.group(5)) + (int(match.group(6)) / 1000000000.0)
                    trace_event.host_timestamp = time.time()

                    buffer.append(trace_event)
                    buffer.sort(key=lambda event: event.timestamp)


        line_buffer = ''
        event_buffer = []
        class TraceEvent():
            event = 0
            status = 0
            src_id = 0
            dst_id = 0
            timestamp = 0.0
            host_timestamp = 0.0
        if process is not None:
            reading_thread = Thread(target=traceEventReader, args=(process, event_buffer,))
            reading_thread.start()


        while True:
            app.processEvents()

            # TODO(themarpe) - move event processing to a separate function
            # Process trace events

            if len(event_buffer) > 0 and time.time() - event_buffer[-1].host_timestamp > 0.2: # atleast 200ms should pass from latest event received
                # TODO(themarpe) - Process events
                pass


        app.exec_()

if __name__ == "__main__":
    main()